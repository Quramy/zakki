# 10/2

## prisma-fabbrica

prisma v5.3.x から出続けていた、DMMF 周りの TypeScript エラー修正。

## dd-trace

Next.js の instrumentation.ts + dd-trace で苦戦中。

https://github.com/DataDog/dd-trace-js/issues/3457#issuecomment-1669499660 にあるように Dynamic Import で Tracer の初期化を行うも、undici にしか計装がかからない。

next plugin が動いてくれないと旨味皆無なんだが。。。

```ts
/* src/insturumentation.ts */

export async function register() {
  if (process.env.NEXT_RUNTIME === "nodejs") {
    const tracerLib = await import("dd-trace");
    const tracer = tracerLib.default;

    tracer.init({ logInjection: true });
    tracer.use("next");
  }
}
```

やっぱり tracer の初期化を行うには、 `register` 関数が呼び出されるのが遅すぎる、という話なんだろうか？

Custom Server なのかなぁ。。このために Custom Server 使うの嫌だなぁ。。。

---

# 10/3

## Tsuquyomi

全然使い物になっていなかった `:TsuReloadProject` を再実装する。

Git branch を切り替えた際に実行することがメインのユースケースなのだけど、

1. バッファには残っているが FS 上から削除されたファイルを tsserver から close する
1. バッファで開き続けているファイルを tsserver へ sync しなおす

を行うようにした。

Git 操作だけでなく、Vim 外の操作( e.g. code generation) によって外部更新された .ts ファイルについても対象となるので、今まで何年も脳死で tsserver とズレが起き出していたら Vim ごと閉じる癖がついてしまっていたのが解消されそう。

## Vim

今更ながら Vim script におけるメソッドとラムダの記法について

```vim
echo len("hogehoge")

" method
echo "hogehoge"->len()

" lambda expr
let Lambda = {i, x -> x * 2} " 左辺は Funcref 型
echo map([1, 2, 3], Lambda)
```

メソッドとラムダを混在させれば以下のように書ける:

```vim
echo [1,2,3]->map({i, x -> x * 2})
```

vim9script だと、ラムダ式のトークンは `->` ではなく、`=>` になるので、メソッド/ラムダの Lexing が行いやすくなっているらしい。
問題はプラグインなどの外部公開するようなコードで vim9script がどの程度受け入れられているのか全然肌感がわからんことだ。

まずは手元の .vimrc を分割して vim9script 化していくのがいいのかねぇ。。

## React

React の cache 関数 ( https://react.dev/reference/react/cache ) で遊んだ。

```tsx
import { cache } from "react";

import DataLoader from "dataloader";

// backend service clients
import { getPopularPosts, getUserById, getUsers } from "@/services";

const memoizedGetUserById = cache(getUserById);

const getUserLoader = () =>
  new DataLoader((id: readonly string[]) =>
    getUsers(id).then((users) => id.map((id) => users.find((u) => u.id === id)))
  );

const memoizedGetUserLoader = cache(getUserLoader);

export async function User({ userId }: { userId: string }) {
  // const result = await memoizedGetUserById(userId);
  const result = await memoizedGetUserLoader().load(userId);
  if (!result) return null;

  const { name, email } = result;

  return (
    <div>
      <p>{name}</p>
      <p>{email}</p>
    </div>
  );
}

export default async function Posts() {
  const posts = await getPopularPosts();
  return posts.map((post) => (
    <ol>
      <li key={post.id}>
        <h3>{post.title}</h3>
        <User userId={post.authorId} />
      </li>
    </ol>
  ));
}
```

特に配列の要素について、Component とデータの取得を collocate させるような設計をしたとすると、React の cache 関数単体だと、N + 1 になる。
上記の例だと、ナイーブな `getUserById` の実行が、Posts の author 人数分発生する。

ここで、 バルクで解決できる実装が提供されている場合、 `getUsers` こいつを Dataloader でくるんでやれば、 N + 1 を解消できる、というのが GraphQL の基本なわけだけど、このテクニックってそのまま RSC の世界でも通用するはず。
GraphQL Resolver でいうところの Execution Context 相当を React.cache から提供するようにすればよいかと思い、やってみたのが上記のコード。

React.cache で Dataloader のインスタンスを返す関数をキャッシュさせれば、Async Component から loader が利用できる。

---

# 10/4

## GraphQL

昨日の RSC + DataLoader の件の続き。

要は RSC の世界観って GraphQL resolvers の実装感覚とかなり似ているはずだ、ということを示すために、同一モデルの Resolver を書き出してみた。

```ts
import { createSchema, createYoga } from "graphql-yoga";

// backend service clients
import { getPopularPosts, getUserById, getUsers } from "@/services";

const typeDefs = gql`
  type Post {
    id: ID!
    title: String!
    author: User
  }

  type User {
    id: ID!
    name: String!
    email: String!
  }

  type Query {
    popularPosts: [Post!]!
  }
`;

const context = () => ({
  userLoader: new DataLoader((id: readonly string[]) =>
    getUsers(id).then((users) => id.map((id) => users.find((u) => u.id === id)))
  ),
});

export const resolvers = {
  User: {},
  Post: {
    author: async ({ authorId }, { userLoader }) => {
      // return await getUserById(authorId); // This may cause N + 1 problem
      return await userLoader.load(authorId);
    },
  },
  Query: {
    popularPosts: async () => {
      return await getPopularPosts();
    },
  },
};

const schema = createSchema({ typeDefs, resolvers });
export const yoga = createYoga({ schema, context });
```

こうして俯瞰してみると、RSC が出た当初、Dan Abramov https://www.youtube.com/watch?v=TQQPAU21ZUw&t=630s の動画で語っていた「(Data fetching の観点でいうと) RSC と GraphQL は同じ問題に対する解法の違いである」と言っていたのが腹落ちする。

App Router って、 SSR + GraphQL Resolver なんだな。 Resolver が特定の Type の fields を返す代わりに、RSC(Async Component) はレンダリング結果 (該当 type の Fragment を Presentation に bind したもの) を返却しているわけで。

一方で Pages Router は SSR + RESTish API で、メンタルモデルとしては古き良き Server Side MVC そのもの。Controller は View が必要とする (末端まで含めた) すべてのデータを Models から引っ張り出さねばならない。View をどれだけ分割しても、そらは本質的には Autonomous じゃない。

Autonomous である、というのは GraphQL においては Fragment Collocation がその実現手段であって「Data と Presentation は High Coherent であるべき」がその思想。
であれば、Public なプロトコルとしての GraphQL が不要であるのであれば、言い換えると React しか Client がないのであれば、Resolver のレベルで Fragment data と Presentation を bind させて返す方が、より High Coherent だ。

---

# 10/5

## GraphQL

ある意味で昨日からの続きのネタなのだけど、DataLoader の重要性に絡んで、GraphQL Type Merge の話をまとめたくなってきたので、サンプルを作る。

https://github.com/Quramy/gql-stitch-with-type-merge-example

## React

`useOptimistic` の使い方を勘違いしていたかも。

Optimistic Update なので Server Action を Invoke したときに Client Side State として 値を更新しておく、というのはまぁ理解していたが、「SA の実行結果と先んじて更新した State が同期するのはいつなんだ」という疑問が残っていた。

答えは、SA 完了時に返却される RSC Protocol の結果が同期される内容だ、という話であった。

## Node.js

`--inspect` を Node.js の起動オプションに食わせてから、Chrome の devtool を立ち上げると Performance 見れるよ、という話

https://nodejs.org/ja/docs/guides/diagnostics/memory/using-heap-profiler

---

# 10/6

## Jotai

少し前から気になっていた Jotai の Atom Family を SSR (Next.js) でどう安全に使えばいいのかについて考えていた

https://twitter.com/Quramy/status/1710341983959703851

https://jotai.org/docs/utilities/family#caveat-memory-leaks にある通り、Family の管理には param を key にした Map が使われているだけ。コードでいうと https://github.com/pmndrs/jotai/blob/v2.4.3/src/vanilla/utils/atomFamily.ts#L22 の辺り。

したがって、以下のようなコードがサーバー側で解釈されたその瞬間から、Map に Key & Value が残存することになり、何もしなければ Memory Leak の要因となる。

```tsx
const myAtomById = atomFamiliy(() => atom(true));

export function MyComponent({ id }) {
  const [value] = useAtom(myAtomById(id));
}
```

ちなみに Recoil では family の Memory Leak が今でもまだオープンなまま

https://zenn.dev/akfm/scraps/2bc577076ef30c

Jotai の場合、コードそのものはかなりシンプルで、 `myAtomById` 自体がそのまま Map の `delete` メソッド相当を公開してくれているので、これをサーバー側で適切なタイミングに叩くことが勝てる。

最初に試したのは、SC で `myAtomById.remove` を呼ぶようなプランだったのだけど、 SC から `myAtomById` を import すると Next.js Compiler に怒られる。
原因は `import { atom } from "jotai"` から推移的に辿れるコードが `useEffect` などの hooks を import しているため。

結局どこかで Client Boundary を切ってからでないと `myAtomById.remove` が実行できない。

それであれば、と、バンドルを最適化する意味で、 `myAtomById` を実行するその CC で remove を実行するプランに変更。

CC で実行する以上、ブラウザ側で動作されると逆に困るため、サーバーでのみ動くようにガードの内側に置く。

```tsx
const myAtomById = atomFamiliy(() => atom(true));

export function MyComponent({ id }) {
  const [value] = useAtom(myAtomById(id));
  if (typeof window === "undefined") {
    myAtomById.remove(id);
  }

  // 以下略
}
```

この CC の SSR が終わった後に、別のコンポーネントから同一の ID で `myAtomById` が呼び出されることもあるが、Initializer Callback が論理的に同じ Atom を構成するのであれば、SSR の文脈では問題ないハズなんだけど、あってるよな...?

上記のコードが安全であるのであれば、 Atom Family そのものを Proxy しておくことで、「メモリリークの心配の無い」 `atomFamily` を作れそう。

```ts
import { type Atom } from "jotai";
import { atomFamily as atomFamilyiDelegate } from "jotai/utils";

export function atomFamily<Param, AtomType extends Atom<unknown>>(
  initializeAtom: (param: Param) => AtomType,
  areEqual?: (a: Param, b: Param) => boolean
) {
  const delegate = atomFamilyiDelegate<Param, AtomType>(
    initializeAtom,
    areEqual
  );
  return new Proxy(delegate, {
    apply: (createAtom, thisArg, [param]: [Param]) => {
      if (typeof window !== "undefined") {
        return createAtom(param);
      }
      const atomItem = createAtom(param);
      Promise.resolve.then(() => createAtom.remove(param));
      return atomItem;
    },
  });
}
```

## Misc

> Elm 作者の Evan さんによる、プログラミング言語プロジェクトの運用に関わるコストと、いろんな言語がどうお金を得ているのかについてのお話。

https://www.youtube.com/watch?v=XZ3w_jec1v8

---

# 10/11

## Web

WebP 周りの知見が溜まってそう:

https://scrapbox.io/dojineko/%E3%83%96%E3%83%A9%E3%82%A6%E3%82%B6%E4%BA%92%E6%8F%9B%E6%80%A7%E3%81%AE%E9%AB%98%E3%81%84%E3%83%A1%E3%83%87%E3%82%A3%E3%82%A2%E5%BD%A2%E5%BC%8F%E3%81%AE%E9%81%B8%E6%8A%9E%E6%97%A9%E8%A6%8B%E8%A1%A8

---

# 10/12

## typed-css-modules

放置しまくりだったので、久しぶりにメンテ。

以前からの問題だった、 css-modoles-loader-core パッケージへの依存を潰す、というのをやる。
その他、 yargs やら glob やらの細かいパッケージも upgrade して audit を green にすることができた。

## GraphQL

GraphQL Conf 関連の Tweet で見かけたネタ。

AppSync が GraphQL Fusion base の gateway 作れるとのことだけど、Fusion って具体の spec どこかに公開されているんだろうか？

Fusion は規約ベースの Distributed GraphQL federation Spec. 仕様そのものは公開されていない。

- https://x.com/Quramy/status/1712374610594066837?s=20
- https://chillicream.com/blog/2023/08/15/graphql-fusion

## typescript-eslint-language-service

こちらもメンテして stale していた Dependencies Update を棚卸しした。

---

# 10/13

## prisma-fabbrica

今日も引き続き OSS メンテ作業として fabbrica を見ることにする。

Open issues であった以下の対応を行った

- https://github.com/Quramy/prisma-fabbrica/issues/195
  - `@unique` なフィールドの自動生成が上手く行かない、という内容. ログを読んでみたら、なぜだか short-uuid の resolve ができてない様子であった
- https://github.com/Quramy/prisma-fabbrica/issues/206
  - `Unsupported` な型宣言がされているフィールドを持つ Model が存在すると generate が失敗する、という内容

195 の方を調査する段階で、fabbrica そのものの Integrated testing の意味合いで入れていた「schema.prisma から生成したコードが TypeScript として Valid かどうか」というテストを見直すことにした。
よくよく考えると、`modelFactory.create` は「 `modelFactory.build` + `prisma.model.create` 」でしかない. `build` に関しては、 DB を用意する必要がなく、ただの Node.js のみの処理として実行できる。
これを考えると、Integrated testing としては「schema.prisma から生成したコードを Jest で実行する」で大半が賄えるので、これに合わせて workspace package 名を変更するなどした。

後者の 206 については、完全にこちらの問題で、自分が下記を知らないだけであった.

> Note: If a model has mandatory Unsupported fields, the generated client will not include create or update methods for that model.

https://www.prisma.io/docs/concepts/components/prisma-schema/data-model#unsupported-types

`create` メソッドが存在しない、ということは DMMF 中に `${model}CreateInput` の構造体もなくなる、という意味なのだが、このエラーハンドリングが抜けていたのでこれを修正.

---

# 10/15

## Prisma

fabbrica の issue を眺めていく過程で、ad-hoc に schema に対する DMMF を確認したくなってきた。
fabbrica の初期開発中にも同じ欲求は当然あったので、雑に `@prisma/internal` のパッケージをブラウザから読み込もうとさせたら、推移依存に Node.js fs が出てきたため、一度頓挫した件。

Import tree は以下のようになっていて、最終的には Engine 側の Rust コードを wasm-binding-gen で Node.js から参照させる流れ。

- https://github.com/prisma/prisma/blob/5.4.2/packages/internals/src/engine-commands/getDmmf.ts
  - https://github.com/prisma/prisma/blob/5.4.2/packages/internals/src/wasm.ts
    - https://github.com/prisma/prisma-engines/blob/5.4.2/prisma-schema-wasm/src/lib.rs#L44

fs への依存がついてくるのは、末端である prisma-schema-wasm の binding gen の生成物であるが、実際のところ `.wasm` ファイルを Read File するためにしか使っていない。
これを、 `fetch` + `InstantiateStreaming` に変えればブラウザでも利用可能そうだったので、patch を当てて実装してみた。

成果物は以下の Repository の GH Pages に Deploy した:

https://github.com/Quramy/prisma-dmmf-viewer

HTML, JS, CSS ぜんぶ Vanilla で書いたのは久しぶり。

---

# 10/16

## jest-prisma

かねてよりの jest-prisma の課題であった Client Extension への対応 (https://github.com/Quramy/jest-prisma/issues/47) について向き合った。

https://github.com/Quramy/jest-prisma/pull/110

Jest environment の Setup 時点では Prisma Client の instantiate を行わず、`beforeEach` のような Transaction 確保時に Client のインスタンスを束縛するように変更した。
こうすることで、 jest の `setupFilesAfterEnv` のタイミングで、Prisma Client instance の設定をユーザーランドに公開することができるようになる (今までは setup 時点で Transaction の元となる `originalClient` を environment に束縛していたため、ユーザー側に拡張の余地を持たせるのが難しかった)

---

# 10/17

## Storybook

Storyshosts で、コンソールにエラーログが流れたときにテストを落とす方法:

```ts
import initStoryshots from "@storybook/addon-storyshots";

let errorLogSpy: jest.SpyInstance<void, any[]>;

describe("Components Rendering", () => {
  beforeAll(() => (errorLogSpy = jest.spyOn(console, "error")));

  initStoryshots();
});

test("Components should not log error", () => {
  expect(errorLogSpy).not.toBeCalled();
});
```

---

# 10/20

## Misc

Web frontend の Prj を立ち上げるときにやっていることって大体が一緒なのだから、自分のやっていること・できることを言語化していきたい。試しに書き出してみる。

30% くらい書いて思ったが、別の md でやったほうがいいな、これ。

### 全体的なアーキテクチャの選定

- Next.js (App Router / Pages Router) どうするの？の検討や合意形成
  - SSR (Server Side Node.js) の有無
    - 最近はそこまで気にされなくなったとはいえ、フロントエンドがサーバー運用することにネガティブを感じる現場もまだある印象
- 基盤構成のキャッチアップ
  - 普段は基本的に AWS 前提 (稀に GCP)
  - 生で EC2 使うのか、Docker 使うとして Fargate なのか EKS なのか、など
  - CDN はどこにいるのか、ロードバランサ (ALB 相当) はどこにいるのか、ブラウザから API サーバーに到達するまでの経路をイメージできるようにしておく

同じ様なコードを書くにせよ nginx に .js や .css を載せるのか、 Node.js のサーバーを Docker Image として用意して Deploy するのかで後続で気にすることは大きく異なる。

### ソースコードの書き方を考える

これを済ませておかないと、「複数人で開発を開始するのが難しい」という系統に絞って考える。

- ライブラリの選定, インストール
  - お約束系:
    - TypeScript, prettier, ESLint あたり
      - この段階で lint のルールについてごちゃごちゃ言っても時間の無駄間があるので、 standard 系の軽めのやつを入れておしまいにしておく
      - 場合によっては Stylelint とかも
  - CSS の書き方を決める
    - CSS in JS or CSS Modules なのか、tailwind を使うのか、のような部分
      - Zero Runtime 系の場合、Meta Framework が用意している Build 周りと親和するかも考慮点
    - 非 atomic css の場合、デザイントークンの管理方法も考えるべき
  - Component UI ライブラリ (Material UI とかそういう系)
    - ちゃんとデザイナーが Sketch や Figma で VD を用意してくれているのであれば、自前で CSS を書いてしまえばよいと思っている
  - State Management
    - Redux とかそういう部分
      - とはいえ、2023 年にもなって Redux を新規に選定することはほぼないはず
    - Atomic State Management なライブラリを検討する方がよい
      - Recoil は非アクティブなため、リスク高い
  - Form ライブラリ
    - React の場合、react-hook-form 一強？
    - RHF だけでなく、resolver (e.g. zod) も検討しておく
  - API 通信方式
    - ここで言っているのは、ブラウザ - Node.js 間の通信ではなく、フロントエンド - バックエンド通信の意。
    - OpenAPI の場合
      - yaml をフロントエンドが書くのか、バックエンドが書くのかによって大きく異なる
      - バックエンドが API 定義を書く場合、openapi-genenerator の設定を行う
      - フロントエンドが API 定義を書く場合、YAML を生成するための TypeScript と親和するツールを用意する(e.g. zodios)
    - GraphQL の場合
      - ランタイムの選定: Apollo Client なのか urql なのか
      - SDL を引っ張ってきて、TypeScript Client 生成を行えるようにする (e.g. graphql-codegen)
    - スタブサーバー
      - バックエンド API を叩くのが面倒、並行開発なのでまだ存在しない、のような場合に検討する
        - そもそもローカルで普通にバックエンド API を動作させた方が楽なのであれば、そっちを使えばよい
      - graphql-mock や MSW を BFF に仕込む、など
  - Component カタログ
    - 実質 Storybook 以外の選択肢が無い
  - テスト関係
    - 最低限の Component Unit Test が書けるくらいのセットアップを事前に済ませておくと楽
    - jest, jest-environment-jsdom, testing-lib, のインストール及び、global な stub の設定など(e.g. Next Router)
- ディレクトリ構成
  - 基本的には選択した Meta Framework の構成に従うようにする
  - Atomic Design を採用しているのであれば、共通コンポーネントディレクトリをどう切るのか、などを考える
  - `utils` のような名前のディレクトリを切ってしまうと将来のゴミ箱になるので、名前はちゃんとかんがえるべき
  - 先に決めておくと楽な箇所
    - ただの関数群: e.g. `src/functions`
    - ライブラリ用グルーコード. Storybook の Decorator や、独自 Redux Middleware: e.g. `src/support/storybook`, `src/support/redux`
- Scaffold
  - hygen や schematics など
  - Component
    - CSS, Storybook, test に何を使うか、及びディレクトリ構成の大まかな検討が完了していれば、Component を自動生成するようにしておく
  - API Client
    - 自分で組むことは無いので、Open API Generator や GraphQL Codegen などの設定と同じ意味
- PoC の作成. 各種ライブラリのセットアップと並行して、各アプリケーション処理方式が想定通り成り立っているかを試していく. いわゆるサンプル実装.
  - API 通信について、正常系だけでなく、非正常系のハンドリング方法も考えておくこと
    - Loading Status はどこから取得するのか, Suspense 使うのか, ...
    - エラーハンドリング は後回しになりがちだが、後から詳細な要件が出てきても改修しやすい仕組み(共通的なエラーハンドリングインターセプタ系統）を噛ませられるようになっているかどうか, ...
  - (SSR を採用している場合)
    - Client Site Routing と Server Side
    - API やその結果の Client State の初期値がどう hydrate されるのかを検証・理解しておく

### BFF 周りの基盤選定

BFF(Backend For Frontend) をフロントエンドで開発・運用する場合に考えること

- 環境変数の取り扱い
  - Server Side に留めるもの (各種 Secret や Backend Service の URL)と、ブラウザまで露出させるべきもの (インターネットから見たサービスの FQDN など) を分別して管理できるようにしておく
- セッション関連
  - 大概が認可とセットになる
  - Redis / DynamoDB などの middleware と結合する箇所の設定
    - express-session や next-session など
- ロギング
  - ローカル開発時以外は構造化ログで出力しておく、など実行環境に合わせてロギングミドルウェア(pino や morgan) の設定を仕込む

### CSS 関連

Prj が走り出してしまうと手を出しにくい部分は以下.

- 共通変数の定義
  - そもそも「どこまで共通変数化するのか」を定める
    - Figma や Sketch の VD が存在している場合、VD に記載されていないものに対して無闇に変数化しても、作業効率が下がるだけ
    - e.g. Figma のカラーパレットに存在するもののみ、Custom Variables に定義するようにする
  - 実装形態は CSS in JS or CSS Modules or Tailwind or ... で異なるが、考え方そのものはあまり変わらないはず
- リセット・ノーマライズ
  - いわゆる UA の標準スタイルを打ち消す系
  - `box-sizing` は後から変更するのが面倒な系統なので、真っ先に対応しておくべき
- ブレークポイントと優先順位
  - レスポンシブ対応が必要な場合、SP First なのか、Laptop First なのかを決めておく
  - 共通定数として保存しておくと楽
    - CSS Modules の場合、 Custom Media 用の PostCSS Plugin を設定しておく
- rem v.s. px どっちを決める
  - 長さに限らず、標準で用いる単位は ある程度 Stylelint で縛っておくとよい

### エラーハンドリングの設計

T.B.D

### カスタムイベント計測

T.B.D

### 計装

T.B.D
